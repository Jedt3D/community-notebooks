{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oject Detection with transformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial from : https://huggingface.co/docs/transformers/tasks/object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install related libraries\n",
    "!pip install -q datasets transformers evaluate timm albumentations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ที่ใช้ในการทำงาน เราจะใช้ `transformers` และ `datasets` มาช่วยในการทำงาน จาก huggingface hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForObjectDetection \n",
    "from transformers import AutoImageProcessor\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torchvision\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import albumentations\n",
    "from PIL import Image, ImageDraw\n",
    "import requests\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login to huggingface_hub\n",
    "# token_id จาก https://huggingface.co/settings/token\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download `cppe-5` dataset เพื่อใช้ในการ train model และ test model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cppe5 = load_dataset(\"cppe-5\")\n",
    "cppe5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สร้าง `id2label` และ `label2id` ของ dataset ที่ใช้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = cppe5[\"train\"].features[\"objects\"].feature[\"category\"].names \n",
    "id2label = {index: x for index, x in enumerate(categories, start=0)} \n",
    "label2id = {v: k for k, v in id2label.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove images with no objects\n",
    "remove_idx = [590, 821, 822, 875, 876, 878, 879] \n",
    "keep = [i for i in range(len(cppe5[\"train\"])) if i not in remove_idx]\n",
    "cppe5[\"train\"] = cppe5[\"train\"].select(keep)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`trasnfrom` data ก่อนที่จะเข้าไปใช้ใน model โดยใช้ `albumentations` ในการทำ data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(480, 480), # resize to 480x480\n",
    "        albumentations.HorizontalFlip(p=1.0), # horizontal flip\n",
    "        albumentations.RandomBrightnessContrast(p=1.0), # random brightness and contrast\n",
    "    ],\n",
    "    bbox_params=albumentations.BboxParams(format=\"coco\", label_fields=[\"category\"]),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define function สำหรับการ train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatted annotations\n",
    "def formatted_anns(image_id, category, area, bbox): \n",
    "    annotations = []\n",
    "    for i in range(0, len(category)):\n",
    "        new_ann = {\n",
    "            \"image_id\": image_id,\n",
    "            \"category_id\": category[i],\n",
    "            \"isCrowd\": 0,\n",
    "            \"area\": area[i],\n",
    "            \"bbox\": list(bbox[i]),\n",
    "        }\n",
    "        annotations.append(new_ann)\n",
    "\n",
    "    return annotations\n",
    "\n",
    "# transforming a batch\n",
    "def transform_aug_ann(examples):\n",
    "    image_ids = examples[\"image_id\"]\n",
    "    images, bboxes, area, categories = [], [], [], []\n",
    "    for image, objects in zip(examples[\"image\"], examples[\"objects\"]):\n",
    "        image = np.array(image.convert(\"RGB\"))[:, :, ::-1]\n",
    "        out = transform(image=image, bboxes=objects[\"bbox\"], category=objects[\"category\"])\n",
    "\n",
    "        area.append(objects[\"area\"])\n",
    "        images.append(out[\"image\"])\n",
    "        bboxes.append(out[\"bboxes\"])\n",
    "        categories.append(out[\"category\"])\n",
    "\n",
    "    targets = [\n",
    "        {\"image_id\": id_, \"annotations\": formatted_anns(id_, cat_, ar_, box_)}\n",
    "        for id_, cat_, ar_, box_ in zip(image_ids, categories, area, bboxes)\n",
    "    ]\n",
    "\n",
    "    return image_processor(images=images, annotations=targets, return_tensors=\"pt\")\n",
    "\n",
    "def collate_fn(batch):\n",
    "    pixel_values = [item[\"pixel_values\"] for item in batch]\n",
    "    encoding = image_processor.pad_and_create_pixel_mask(pixel_values, return_tensors=\"pt\")\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "    batch = {}\n",
    "    batch[\"pixel_values\"] = encoding[\"pixel_values\"]\n",
    "    batch[\"pixel_mask\"] = encoding[\"pixel_mask\"]\n",
    "    batch[\"labels\"] = labels\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainfrom cppe5 model with augmentation\n",
    "cppe5[\"train\"] = cppe5[\"train\"].with_transform(transform_aug_ann)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เลือก pretrain_model และ image processor ที่จะใช้\n",
    "checkpoint = \"facebook/detr-resnet-50\" \n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# สร้าง model จาก pretrain_model ที่เลือก\n",
    "model = AutoModelForObjectDetection.from_pretrained(\n",
    "    checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "กำหนด `training_args` และ `trainer` สำหรับการเทรนโมเดล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [optional] disable wandb ที่ใช้ในการ log ข้อมูล\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"cppe5_10ep\", # ชื่อโฟลเดอร์ที่เราจะเก็บ model ที่ train ได้\n",
    "    per_device_train_batch_size=2, # จำนวน batch size \n",
    "    num_train_epochs=10,  # จำนวน epoch ที่เราต้องการให้โมเดล train\n",
    "    fp16=True, # ใช้ mixed precision หรือไม่\n",
    "    save_steps=200, # จำนวน step ที่เราต้องการให้โมเดล save\n",
    "    logging_steps=50, \n",
    "    learning_rate=1e-5, # ค่า learning rate\n",
    "    weight_decay=1e-4, # ค่า weight decay\n",
    "    save_total_limit=2, # จำนวน model ที่เราต้องการให้โมเดล save\n",
    "    remove_unused_columns=False, \n",
    "    push_to_hub=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# สร้าง trainer จาก model ที่เราสร้างไว้\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=collate_fn,\n",
    "    train_dataset=cppe5[\"train\"],\n",
    "    tokenizer=image_processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train() # train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub() # push model ไปยัง huggingface_hub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "โดยหลังจาก `trainer.push_to_hub()` model ของเราจะอยู่บน huggingface hub สามารถเรียกใช้ได้โดยใช้ `model_id` ที่ได้จากการ push model ขึ้นไป"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ทดสอบ model หรือ `evaluation` เพื่อเช็คผลลัพธ์ของโมเดล "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDetection(torchvision.datasets.CocoDetection):\n",
    "    def __init__(self, img_folder, feature_extractor, ann_file):\n",
    "        super().__init__(img_folder, ann_file)\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # read in PIL image and target in COCO format\n",
    "        img, target = super(CocoDetection, self).__getitem__(idx)\n",
    "\n",
    "        # preprocess image and target: converting target to DETR format,\n",
    "        # resizing + normalization of both image and target)\n",
    "        image_id = self.ids[idx]\n",
    "        target = {\"image_id\": image_id, \"annotations\": target}\n",
    "        encoding = self.feature_extractor(images=img, annotations=target, return_tensors=\"pt\")\n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze()  # remove batch dimension\n",
    "        target = encoding[\"labels\"][0]  # remove batch dimension\n",
    "\n",
    "        return {\"pixel_values\": pixel_values, \"labels\": target}\n",
    "\n",
    "\n",
    "# format annotations the same as for training, no need for data augmentation\n",
    "def val_formatted_anns(image_id, objects):\n",
    "    annotations = []\n",
    "    for i in range(0, len(objects[\"id\"])):\n",
    "        new_ann = {\n",
    "            \"id\": objects[\"id\"][i],\n",
    "            \"category_id\": objects[\"category\"][i],\n",
    "            \"iscrowd\": 0,\n",
    "            \"image_id\": image_id,\n",
    "            \"area\": objects[\"area\"][i],\n",
    "            \"bbox\": objects[\"bbox\"][i],\n",
    "        }\n",
    "        annotations.append(new_ann)\n",
    "\n",
    "    return annotations\n",
    "\n",
    "\n",
    "# Save images and annotations into the files torchvision.datasets.CocoDetection expects\n",
    "def save_cppe5_annotation_file_images(cppe5):\n",
    "    output_json = {}\n",
    "    path_output_cppe5 = f\"{os.getcwd()}/cppe5/\"\n",
    "\n",
    "    if not os.path.exists(path_output_cppe5):\n",
    "        os.makedirs(path_output_cppe5)\n",
    "\n",
    "    path_anno = os.path.join(path_output_cppe5, \"cppe5_ann.json\")\n",
    "    categories_json = [{\"supercategory\": \"none\", \"id\": id, \"name\": id2label[id]} for id in id2label]\n",
    "    output_json[\"images\"] = []\n",
    "    output_json[\"annotations\"] = []\n",
    "    for example in cppe5:\n",
    "        ann = val_formatted_anns(example[\"image_id\"], example[\"objects\"])\n",
    "        output_json[\"images\"].append(\n",
    "            {\n",
    "                \"id\": example[\"image_id\"],\n",
    "                \"width\": example[\"image\"].width,\n",
    "                \"height\": example[\"image\"].height,\n",
    "                \"file_name\": f\"{example['image_id']}.png\",\n",
    "            }\n",
    "        )\n",
    "        output_json[\"annotations\"].extend(ann)\n",
    "    output_json[\"categories\"] = categories_json\n",
    "\n",
    "    with open(path_anno, \"w\") as file:\n",
    "        json.dump(output_json, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    for im, img_id in zip(cppe5[\"image\"], cppe5[\"image_id\"]):\n",
    "        path_img = os.path.join(path_output_cppe5, f\"{img_id}.png\")\n",
    "        im.save(path_img)\n",
    "\n",
    "    return path_output_cppe5, path_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"{username}/{directory_name}\" # ใส่ directory ของ model ที่เราเทรนไว้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เลือก processor จาก model ที่เรา train ไว้\n",
    "im_processor = AutoImageProcessor.from_pretrained(model_id)\n",
    "path_output_cppe5, path_anno = save_cppe5_annotation_file_images(cppe5[\"test\"])\n",
    "test_ds_coco_format = CocoDetection(path_output_cppe5, im_processor, path_anno)\n",
    "\n",
    "# เลือก model ที่เรา train ไว้\n",
    "model = AutoModelForObjectDetection.from_pretrained(model_id)\n",
    "module = evaluate.load(\"ybelkada/cocoevaluate\", coco=test_ds_coco_format.coco)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    test_ds_coco_format, batch_size=2, shuffle=False, num_workers=0, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# prediction และ evaluation\n",
    "with torch.no_grad():\n",
    "    for idx, batch in enumerate(tqdm(val_dataloader)):\n",
    "        pixel_values = batch[\"pixel_values\"]\n",
    "        pixel_mask = batch[\"pixel_mask\"]\n",
    "\n",
    "        labels = [\n",
    "            {k: v for k, v in t.items()} for t in batch[\"labels\"]\n",
    "        ]  # these are in DETR format, resized + normalized\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
    "\n",
    "        orig_target_sizes = torch.stack([target[\"orig_size\"] for target in labels], dim=0)\n",
    "        results = im_processor.post_process(outputs, orig_target_sizes)  # convert outputs of model to COCO api\n",
    "\n",
    "        module.add(prediction=results, reference=labels)\n",
    "        del batch\n",
    "\n",
    "results = module.compute()\n",
    "\n",
    "# แสดงผล evaluation\n",
    "print(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction `trainer.predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เลือกรูปที่ต้องการ predict จาก url\n",
    "url = \"https://i.imgur.com/2lnWoly.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"{username}/{directory_name}\" # ใส่ directory ของ model ที่เราเทรนไว้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = AutoImageProcessor.from_pretrained(model_id)  # processor \n",
    "model = AutoModelForObjectDetection.from_pretrained(model_id) # model \n",
    "\n",
    "# predict image\n",
    "with torch.no_grad():\n",
    "    inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    target_sizes = torch.tensor([image.size[::-1]])\n",
    "    results = image_processor.post_process_object_detection(outputs, threshold=0.5, target_sizes=target_sizes)[0] # ใส่ threshold ที่เหมาะสม "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`thesold` เราสามารถเปลี่ยนค่าได้ตามความเหมาะสม เนื่องจากในบาง model ที่เราเทรนไว้ จะมีค่า confidence ของการ `prediction` ที่ต่างกัน"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize results\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    print(\n",
    "        f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
    "        f\"{round(score.item(), 3)} at location {box}\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize prediction โดยใช้ `ImageDraw` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    x, y, x2, y2 = tuple(box)\n",
    "    draw.rectangle((x, y, x2, y2), outline=\"red\", width=1)\n",
    "    draw.text((x, y), model.config.id2label[label.item()], fill=\"white\")\n",
    "\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
